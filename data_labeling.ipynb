{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checklist for logs: \n",
    "\n",
    "|job ID|log| reason acc. to elasticsearch | reason acc to script| |\n",
    "|-|----------|----------|----------|-----|\n",
    "| baf77c21-bdd5-0aa2-8731-000000000385|9ef7ce17ae108085e8a26e1f2046e1cf73e8c976.json|Infrastructure - Matlab License |Infrastructure - Matlab License |y|\n",
    "| 86623622-6e74-9368-74a8-000000000028|882dafcc748b4f0695ce486241a05ad2.json|?| Test(s) failed|y|\n",
    "|16911dd9-d58b-df18-7329-000000000ba3|e850514f59cb3334754f2641fc63f20f46af56e7.json|FuSa Violation found|Main Category: FuSa Violation Found (Check 'bazel_wrapper_log.txt' on the logs folder), Subcategory: , Pattern: Failed actions detected in bazel_wrapper_log.txt file|y|\n",
    "|No ID provided||?|redirected output - Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components, Subcategory: Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components|?|\n",
    "|No ID provided||?| redirected output - default, Subcategory: default|?|\n",
    "|c65a4cd1-edf7-790d-cd51-000000000042|0752ac127d21a70af1765ae29afc53d978224f25.json|python|Test(s) failed, Subcategory: |?|\n",
    "|No ID provided||python|Main Category: python, Subcategory: ,|y||\n",
    "|b6d2a4bc-700f-7546-f838-000000000042|8e89be688f5b331654a6f44975a7c6c23dd3b71c.json|Compiler (gnu)  | Bazel - error executing command, Subcategory: error executing command|X|\n",
    "||00e0b3d030f7fd0eef0c4b016e3d5e7e2b51a69f.json|Bazel (failed on target analysis)|Not flagged / No match found|X|\n",
    "|No ID provided|b819bae8dfb1923b8f9dc3c1b4bb2eed8c3fa2a3.json|Compiler (clang)|Bazel - error executing command, Subcategory: error executing command|X|\n",
    "|NO ID provided|cd5c0bbd5821d9d31f41442f78bcae86221e65a0.json|Bazel(missing input file)|Bazel - missing input file, Subcategory: missing input file, Pattern: ERROR:(.*)input file\\(s\\) do not exist |?|\n",
    "|NO ID provided||Bazel(missing input file)|Bazel - missing input file, Subcategory: missing input file, Pattern: ERROR:(.*)missing input file '.*' |?|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches found in file: preprocessed_logs\\00628c96780941e8f1ffd78804d7da1e7bcf32417fbf3b476b1ea877f4ab44e4__job-output_cropped.json\n",
      "No matches found in file: preprocessed_logs\\0062e5a17f0c5832bf20d4f810fd448701afd48426f87de5a448d6bc198abae2__job-output_cropped.json\n",
      "No matches found in file: preprocessed_logs\\00708c33771b342dab6bc70612ebbda2d80d22abae3d95ff96ac10156500f72b__job-output_cropped.json\n",
      "No matches found in file: preprocessed_logs\\00e0b3d030f7fd0eef0c4b016e3d5e7e2b51a69f_cropped.json\n",
      "File: preprocessed_logs\\005fc583d4745e2470010c57b6422bcbc5c5fb0e271a7f11d72248e702e1090a__job-output_cropped.json\n",
      "  Task: Run docker command (ID: 2aa698b8-b2fd-a900-8da6-000000000038)\n",
      "    Error Cluster: Test(s) failed, Error Type: , Pattern: \\/\\/.*\\s+FAILED in [0-9.]+s\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\00609ed82bfdb509cf935a6101a636b891e25ef1a08268849b236609f42650d3__job-output_cropped.json\n",
      "  Task: Running build 0 with runner (ID: 620460c8-edcb-fb02-f8d4-000000000425)\n",
      "    Error Cluster: Test(s) failed, Error Type: , Pattern: \\/\\/.*\\s+FAILED in [0-9.]+s\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\0063c906e5290ca5c11bc7c8efba154fc8dcbcb03643bcda0f54f793bd9af5b5__job-output_cropped.json\n",
      "  Task: Run docker command (ID: ea446e25-7667-a36d-6c98-000000000033)\n",
      "    Error Cluster: Test(s) failed, Error Type: , Pattern: \\/\\/.*\\s+FAILED in [0-9.]+s\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\0065bc74ca0b24d30a11b96a73f1fb8588a624962b67bec41fcde6a862c5acb9__job-output_cropped.json\n",
      "  Task: Run docker command (ID: aa463074-4aee-806c-398d-0000000000d2)\n",
      "    Error Cluster: Bazel - error executing command, Error Type: error executing command, Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\0067a8788a1a5e30cecc3c159a8f5b6546a46cd5fb18253c82de30e8d1e7a988__job-output_cropped.json\n",
      "  Task: Run docker command (ID: fec01ff5-970b-89c8-db0d-00000000004d)\n",
      "    Error Cluster: Test(s) failed to build, Error Type: , Pattern: \\/\\/.*\\s+FAILED TO BUILD[$]?\n",
      "    Error Cluster: Bazel - error executing command, Error Type: error executing command, Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\0077401c9568efb6267a2c6ffd1e696ffe70e479d7c5e69413d3d7aea3105035__job-output_cropped.json\n",
      "  Task: Run docker command (ID: 5e31fc0c-7743-17c7-e392-00000000004d)\n",
      "    Error Cluster: Test(s) failed to build, Error Type: , Pattern: \\/\\/.*\\s+FAILED TO BUILD[$]?\n",
      "    Error Cluster: Bazel - error executing command, Error Type: error executing command, Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\0079e5bcee8a7318e88e6d40be15c242ad522e2af6cbc1cdbeecf4beb0e743c7__job-output_cropped.json\n",
      "  Task: Trigger TestGuide Connector (ID: ee176fa9-7af9-a6a0-2034-000000000725)\n",
      "    Error Cluster: Test Guide - connector, Error Type: connector, Pattern: \\[INFO \\] .* Test Guide connector terminated with error...\n",
      "  Task: Evaluate test results (Linux) (ID: ee176fa9-7af9-a6a0-2034-000000000a5d)\n",
      "    Error Cluster: Test Guide - Tests failing, Error Type: Tests failing, Pattern: Tests still failing after all excludes\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\0752ac127d21a70af1765ae29afc53d978224f25_cropped.json\n",
      "  Task: Run docker command (ID: c65a4cd1-edf7-790d-cd51-00000000004d)\n",
      "    Error Cluster: Test(s) failed, Error Type: , Pattern: \\/\\/.*\\s+FAILED in [0-9]* out of [0-9]*\n",
      "  Task: Get failed targets, archive detailed test logs and create message (ID: c65a4cd1-edf7-f4e1-1a52-000000000005)\n",
      "    Error Cluster: python, Error Type: , Pattern: ^(.*Traceback.+\\n( .+\\n)+(?P<type>\\S.+Error.*?):.+\\n?(?P<details>(\\s.+\\n)*)?)+\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\882dafcc748b4f0695ce486241a05ad2_cropped.json\n",
      "  Task: Run docker command (ID: 86623622-6e74-9368-74a8-000000000033)\n",
      "    Error Cluster: Test(s) failed, Error Type: , Pattern: \\/\\/.*\\s+FAILED in [0-9]* out of [0-9]*\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\8e89be688f5b331654a6f44975a7c6c23dd3b71c_cropped.json\n",
      "  Task: Run docker command (ID: b6d2a4bc-700f-7546-f838-00000000004d)\n",
      "    Error Cluster: Bazel - error executing command, Error Type: error executing command, Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\9ef7ce17ae108085e8a26e1f2046e1cf73e8c976_cropped.json\n",
      "  Task: Run docker command (ID: baf77c21-bdd5-0aa2-8731-000000000390)\n",
      "    Error Cluster: Infrastructure - Matlab License, Error Type: , Pattern: License checkout failed.\n",
      "    Error Cluster: Bazel - error executing command, Error Type: error executing command, Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\b819bae8dfb1923b8f9dc3c1b4bb2eed8c3fa2a3_cropped.json\n",
      "  Task: Exec (ID: 2adfc6b1-10cd-e369-e81f-000000000131)\n",
      "    Error Cluster: Bazel - error executing command, Error Type: error executing command, Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\cd5c0bbd5821d9d31f41442f78bcae86221e65a0_cropped.json\n",
      "  Task: Exec (ID: 9e5df66f-7178-4416-1be0-000000000131)\n",
      "    Error Cluster: Bazel - missing input file, Error Type: missing input file, Pattern: ERROR:(.*)input file\\(s\\) do not exist\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "File: preprocessed_logs\\e850514f59cb3334754f2641fc63f20f46af56e7_cropped.json\n",
      "  Task: Run docker command (ID: 16911dd9-d58b-df18-7329-000000000bb7)\n",
      "    Error Cluster: FuSa Violation Found (Check 'bazel_wrapper_log.txt' on the logs folder), Error Type: , Pattern: Failed actions detected in bazel_wrapper_log.txt file\n",
      "  Task: Postprocess summary and report (ID: 16911dd9-d58b-df18-7329-000000000d5f)\n",
      "    Error Cluster: redirected output - Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components, Error Type: Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components, Pattern: ^@tu-cc-ci-adp-github-eof(?:(?:\\s+type:(?P<type>\\S*))|(?:\\s+file:(?P<file>\\S*))|(?:\\s+line:(?P<line>\\S*)))*\\s+(?P<details>(?:.|[\\r\\n])*(- Check-Bazel-rules-in-FuSa-critical-components)(?:.|[\\r\\n])*)\n",
      "    Error Cluster: redirected output - default, Error Type: default, Pattern: ^@tu-cc-ci-adp-github-eof(?:(?:\\s+type:(?P<type>\\S*))|(?:\\s+file:(?P<file>\\S*))|(?:\\s+line:(?P<line>\\S*)))*\\s+(?P<details>(?:.|[\\r\\n])*)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import textwrap\n",
    "import extract_build_failures.error_patterns as error_patterns\n",
    "\n",
    "INFRA_PATTERNS = error_patterns.INFRA_PATTERNS\n",
    "BUILD_PATTERNS = error_patterns.BUILD_PATTERNS\n",
    "\n",
    "def restructure_patterns(patterns):\n",
    "    restructured_patterns = {}\n",
    "    for pattern_type, subpatterns in patterns.items():\n",
    "        if isinstance(subpatterns, (set, list)):\n",
    "            restructured_patterns[pattern_type] = {\"\": list(subpatterns)}\n",
    "        elif isinstance(subpatterns, dict):\n",
    "            restructured_patterns[pattern_type] = {}\n",
    "            for subtype, regex_list in subpatterns.items():\n",
    "                if isinstance(regex_list, (list, set)):\n",
    "                    restructured_patterns[pattern_type][subtype] = list(regex_list)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected type for regex list: {type(regex_list)}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected type for subpatterns: {type(subpatterns)}\")\n",
    "    return restructured_patterns\n",
    "\n",
    "def compile_patterns(patterns_dict):\n",
    "    compiled_patterns = {}\n",
    "    for main_category, subpatterns in patterns_dict.items():\n",
    "        for sub_category, patterns in subpatterns.items():\n",
    "            compiled_patterns.setdefault((main_category, sub_category), []).extend([re.compile(pattern) for pattern in patterns])\n",
    "    return compiled_patterns\n",
    "\n",
    "def check_log_entry(log_entry, compiled_patterns):\n",
    "    matches = []\n",
    "    for (main_category, sub_category), regex_list in compiled_patterns.items():\n",
    "        for regex in regex_list:\n",
    "            for match in regex.finditer(log_entry):\n",
    "                category = f\"{main_category} - {sub_category}\" if sub_category else main_category\n",
    "                matches.append((category, sub_category, regex.pattern))\n",
    "    return matches\n",
    "\n",
    "def process_single_log_file(file_path, compiled_patterns):\n",
    "    summary = {'tasks_summary': {}}\n",
    "    task_matches = {}\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        log_entries = json.load(file)\n",
    "        for log in log_entries:\n",
    "            task_id = log.get('id', 'No ID provided')\n",
    "            name = log.get('name', 'No task name provided')\n",
    "            task_key = f\"{name} (ID: {task_id})\"\n",
    "            summary['tasks_summary'].setdefault(task_key, 0)\n",
    "            summary['tasks_summary'][task_key] += 1\n",
    "\n",
    "            stdout_text = \"\\n\".join(log.get('stdout_lines', []))\n",
    "            matches = check_log_entry(stdout_text, compiled_patterns)\n",
    "            if matches:\n",
    "                if task_key not in task_matches:\n",
    "                    task_matches[task_key] = []\n",
    "                task_matches[task_key].extend(matches)\n",
    "\n",
    "    return summary, task_matches\n",
    "\n",
    "def process_log_files(directory_path, compiled_patterns):\n",
    "    final_summary = {'tasks_summary': {}}\n",
    "    file_matches = {}\n",
    "\n",
    "    for filename in filter(lambda f: f.endswith('.json'), os.listdir(directory_path)):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        summary, task_matches = process_single_log_file(file_path, compiled_patterns)\n",
    "\n",
    "        for task_key, count in summary['tasks_summary'].items():\n",
    "            final_summary['tasks_summary'].setdefault(task_key, 0)\n",
    "            final_summary['tasks_summary'][task_key] += count\n",
    "\n",
    "        if task_matches:\n",
    "            file_matches[file_path] = task_matches\n",
    "        else:\n",
    "            print(f\"No matches found in file: {file_path}\")  # Debugging output\n",
    "\n",
    "    return final_summary, file_matches\n",
    "\n",
    "def format_summary_to_screen_width(summary, terminal_width=150):\n",
    "    formatted_summary = \"\"\n",
    "    for key, value in summary.items():\n",
    "        if isinstance(value, dict):\n",
    "            formatted_summary += f\"{key}:\\n\"\n",
    "            for sub_key, sub_value in value.items():\n",
    "                wrapped_sub_value = textwrap.fill(str(sub_value), terminal_width - 4)\n",
    "                formatted_summary += f\"  {sub_key}: {wrapped_sub_value}\\n\"\n",
    "        else:\n",
    "            wrapped_value = textwrap.fill(str(value), terminal_width)\n",
    "            formatted_summary += f\"{key}: {wrapped_value}\\n\"\n",
    "        formatted_summary += \"-\" * terminal_width + \"\\n\"\n",
    "    return formatted_summary\n",
    "\n",
    "def format_file_matches(file_matches, terminal_width=150):\n",
    "    formatted_matches = \"\"\n",
    "    for file_path, tasks in file_matches.items():\n",
    "        formatted_matches += f\"File: {file_path}\\n\"\n",
    "        for task_key, matches in tasks.items():\n",
    "            formatted_matches += f\"  Task: {task_key}\\n\"\n",
    "            unique_clusters = set()\n",
    "            for match in matches:\n",
    "                error_cluster, error_type, pattern = match\n",
    "                if error_cluster not in unique_clusters:\n",
    "                    unique_clusters.add(error_cluster)\n",
    "                    formatted_matches += f\"    Error Cluster: {error_cluster}, Error Type: {error_type}, Pattern: {pattern}\\n\"\n",
    "        formatted_matches += \"-\" * terminal_width + \"\\n\"\n",
    "    return formatted_matches\n",
    "\n",
    "def main():\n",
    "    # Restructure the patterns first\n",
    "    restructured_infra_patterns = restructure_patterns(INFRA_PATTERNS)\n",
    "    restructured_build_patterns = restructure_patterns(BUILD_PATTERNS)\n",
    "\n",
    "    # Compile the restructured patterns\n",
    "    compiled_infra_patterns = compile_patterns(restructured_infra_patterns)\n",
    "    compiled_build_patterns = compile_patterns(restructured_build_patterns)\n",
    "\n",
    "    # Combine all compiled patterns\n",
    "    all_compiled_patterns = {**compiled_infra_patterns, **compiled_build_patterns}\n",
    "\n",
    "    # Process log files\n",
    "    directory_path = 'preprocessed_logs'\n",
    "    summary, file_matches = process_log_files(directory_path, all_compiled_patterns)\n",
    "\n",
    "    # Format and print the file matches\n",
    "    formatted_file_matches = format_file_matches(file_matches)\n",
    "    print(formatted_file_matches)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
