{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checklist for logs: \n",
    "\n",
    "|job ID|log| reason acc. to elasticsearch | reason acc to script| |\n",
    "|-|----------|----------|----------|-----|\n",
    "| baf77c21-bdd5-0aa2-8731-000000000385|9ef7ce17ae108085e8a26e1f2046e1cf73e8c976.json|Infrastructure - Matlab License |Infrastructure - Matlab License |y|\n",
    "| 86623622-6e74-9368-74a8-000000000028|882dafcc748b4f0695ce486241a05ad2.json|?| Test(s) failed|y|\n",
    "|16911dd9-d58b-df18-7329-000000000ba3|e850514f59cb3334754f2641fc63f20f46af56e7.json|FuSa Violation found|Main Category: FuSa Violation Found (Check 'bazel_wrapper_log.txt' on the logs folder), Subcategory: , Pattern: Failed actions detected in bazel_wrapper_log.txt file|y|\n",
    "|No ID provided||?|redirected output - Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components, Subcategory: Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components|?|\n",
    "|No ID provided||?| redirected output - default, Subcategory: default|?|\n",
    "|c65a4cd1-edf7-790d-cd51-000000000042|0752ac127d21a70af1765ae29afc53d978224f25.json|python|Test(s) failed, Subcategory: |?|\n",
    "|No ID provided||python|Main Category: python, Subcategory: ,|y||\n",
    "|b6d2a4bc-700f-7546-f838-000000000042|8e89be688f5b331654a6f44975a7c6c23dd3b71c.json|Compiler (gnu)  | Bazel - error executing command, Subcategory: error executing command|X|\n",
    "||00e0b3d030f7fd0eef0c4b016e3d5e7e2b51a69f.json|Bazel (failed on target analysis)|Not flagged / No match found|X|\n",
    "|No ID provided|b819bae8dfb1923b8f9dc3c1b4bb2eed8c3fa2a3.json|Compiler (clang)|Bazel - error executing command, Subcategory: error executing command|X|\n",
    "|NO ID provided|cd5c0bbd5821d9d31f41442f78bcae86221e65a0.json|Bazel(missing input file)|Bazel - missing input file, Subcategory: missing input file, Pattern: ERROR:(.*)input file\\(s\\) do not exist |?|\n",
    "|NO ID provided||Bazel(missing input file)|Bazel - missing input file, Subcategory: missing input file, Pattern: ERROR:(.*)missing input file '.*' |?|\n",
    "\n",
    "Why same file gets \"unknown error\" & a match? -->  Because 18 logs but 34 errors - Needs Dealing with\n",
    "- 005fc583d4745e2470010c57b6422bcbc5c5fb0e271a7f11d72248e702e1090a (2 times)\n",
    "- 0067a8788a1a5e30cecc3c159a8f5b6546a46cd5fb18253c82de30e8d1e7a988 (4 times)\n",
    "- 0077401c9568efb6267a2c6ffd1e696ffe70e479d7c5e69413d3d7aea3105035 (4 times)\n",
    "- e850514f59cb3334754f2641fc63f20f46af56e7 (6 times)\n",
    "- 0079e5bcee8a7318e88e6d40be15c242ad522e2af6cbc1cdbeecf4beb0e743c7 (3 times)\n",
    "- 0752ac127d21a70af1765ae29afc53d978224f25 (4 times)\n",
    "- 8e89be688f5b331654a6f44975a7c6c23dd3b71c (3 times)\n",
    "- 9ef7ce17ae108085e8a26e1f2046e1cf73e8c976 (2 times)\n",
    "- cd5c0bbd5821d9d31f41442f78bcae86221e65a0 (2 times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import error_patterns\n",
    "import re\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "INFRA_PATTERNS = error_patterns.INFRA_PATTERNS\n",
    "BUILD_PATTERNS = error_patterns.BUILD_PATTERNS\n",
    "\n",
    "# compile patterns from error_patterns.py\n",
    "def compile_patterns(patterns_dict):\n",
    "    compiled_patterns = {}\n",
    "    for main_category, patterns in patterns_dict.items():\n",
    "        if isinstance(patterns, dict):\n",
    "            for sub_category, sub_patterns in patterns.items():\n",
    "                for pattern in sub_patterns:\n",
    "                    compiled_patterns.setdefault((main_category, sub_category), []).append(re.compile(pattern))\n",
    "        else:\n",
    "            for pattern in patterns:\n",
    "                compiled_patterns.setdefault((main_category, \"\"), []).append(re.compile(pattern))\n",
    "    return compiled_patterns\n",
    "\n",
    "\n",
    "# check log entry against patterns\n",
    "def check_log_entry(log_entry, compiled_patterns):\n",
    "    matches = []\n",
    "    for (main_category, sub_category), regex_list in compiled_patterns.items():\n",
    "        for regex in regex_list:\n",
    "            if regex.search(log_entry):\n",
    "                category = f\"{main_category} - {sub_category}\" if sub_category else main_category\n",
    "                matches.append((category, sub_category, regex.pattern))\n",
    "    return matches\n",
    "\n",
    "# process files\n",
    "def process_log_files(directory_path, compiled_patterns):\n",
    "    summary = {\n",
    "        'tasks_summary': {},\n",
    "        'msg_summary': {}\n",
    "    }\n",
    "    for filename in filter(lambda f: f.endswith('.json'), os.listdir(directory_path)):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            log_entries = json.load(file)\n",
    "            for log in log_entries:\n",
    "                task_id = log.get('id', 'No ID provided')\n",
    "                name = log.get('name', 'No task name provided')\n",
    "                msg = log['msg']\n",
    "                task_key = f\"{name} (ID: {task_id})\"\n",
    "                summary['tasks_summary'].setdefault(task_key, 0)\n",
    "                summary['tasks_summary'][task_key] += 1\n",
    "                summary['msg_summary'].setdefault(msg, 0)\n",
    "                summary['msg_summary'][msg] += 1\n",
    "\n",
    "                stdout_text = \"\\n\".join(log.get('stdout_lines', []))\n",
    "                matches = check_log_entry(stdout_text, compiled_patterns)\n",
    "                for match in matches:\n",
    "                    main_category, sub_category, pattern = match\n",
    "                    print(f\"Current File: {file_path}\")\n",
    "                    print(task_key)\n",
    "                    print(f\"Main Category: {main_category}, Subcategory: {sub_category}, Pattern: {pattern}\")\n",
    "    return summary\n",
    "\n",
    "# format summary for readability\n",
    "def format_summary_to_screen_width(summary, terminal_width=150):\n",
    "    formatted_summary = \"\"\n",
    "    for key, value in summary.items():\n",
    "        if isinstance(value, dict):\n",
    "            formatted_summary += f\"{key}:\\n\"\n",
    "            for sub_key, sub_value in value.items():\n",
    "                wrapped_sub_value = textwrap.fill(str(sub_value), terminal_width - 4)\n",
    "                formatted_summary += f\"  {sub_key}: {wrapped_sub_value}\\n\"\n",
    "        else:\n",
    "            wrapped_value = textwrap.fill(str(value), terminal_width)\n",
    "            formatted_summary += f\"{key}: {wrapped_value}\\n\"\n",
    "        formatted_summary += \"-\" * terminal_width + \"\\n\"\n",
    "    return formatted_summary\n",
    "\n",
    "# Usage:\n",
    "compiled_infra_patterns = compile_patterns(INFRA_PATTERNS)\n",
    "compiled_build_patterns = compile_patterns(BUILD_PATTERNS)\n",
    "directory_path = 'preprocessed_logs'\n",
    "all_compiled_patterns = {**compiled_infra_patterns, **compiled_build_patterns}\n",
    "logs_directory_path = 'logs'\n",
    "output_directory_path = 'preprocessed_logs'\n",
    "\n",
    "summary = process_log_files(directory_path, all_compiled_patterns)\n",
    "formatted_summary = format_summary_to_screen_width(summary)\n",
    "print(formatted_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
