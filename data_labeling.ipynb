{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiled_infra_pattern: \n",
    "\n",
    "{('Infrastructure', ''): [re.compile('Unexpected failure during module execution.'), re.compile('Failed to update apt cache'), re.compile('^.+extended fault data: .+'), re.compile('WebException .+'), re.compile('HTTP error \\\\d+ .+')], ('Infrastructure', 'Host unreachable'): [re.compile('(Data could not be sent to remote host|Make sure this host can be reached|No address associated with hostname).+$')], ('Infrastructure - Ansible', ''): [re.compile('Timeout \\\\(.*\\\\) waiting for privilege escalation prompt')], ('Infrastructure - Artifactory', ''): [re.compile('\\\\[Error\\\\].* Artifactory response: (?P<type>.+)\\\\n<.+>\\\\n(?P<details>[^<]+)'), re.compile('\\\\[Error\\\\].* Artifactory response: (?P<type>.+)(\\\\n(.+\\\\n)*.+errors[^{]+{\\\\n(?P<details>[^{}]+)})?'), re.compile('^.*http.client.IncompleteRead: IncompleteRead.*'), re.compile('unauthorized: The client does not have permission to push to the repository'), re.compile('ConnectionError: .+artifactory\\\\.cc\\\\.bmwgroup\\\\.net.*$'), re.compile('Failure downloading https:\\\\/\\\\/(.*)artifactory.cc.bmwgroup.net\\\\/(.*), Connection failure: The read operation timed out'), re.compile(\"Error downloading 'https:\\\\/\\\\/(.*)\\\\.artifactory\\\\.cc\\\\.bmwgroup\\\\.net(.*)The remote name could not be resolved: '(.*)\\\\.artifactory\\\\.cc\\\\.bmwgroup\\\\.net'\"), re.compile('artifactory-cc-bmwgroup-net-artifactory.*connection reset by peer$')], ('Infrastructure - Artifactory', 'Bazel download error'): [re.compile('could not download Bazel:.+unable to complete request.+$')], ('Infrastructure - Artifactory', 'Download error'): [re.compile('could not download .* failed with error.*$')], ('Infrastructure - Artifactory', 'Unexpected EOF'): [re.compile('could not download .* unexpected EOF$')], ('Infrastructure - Artifactory', 'Checksum mismatch'): [re.compile('Error in download: java\\\\.io\\\\.IOException: Error downloading \\\\[.+\\\\] to .+: Checksum was [a-f0-9]+ but wanted [a-f0-9]+')], ('Infrastructure - Artifactory', 'Content-Length mismatch'): [re.compile('Error downloading\\\\s\\\\[http(s)?:\\\\/\\\\/(\\\\w+)\\\\.artifactory\\\\.cc\\\\.bmwgroup\\\\.net\\\\/artifactory\\\\/.* Bytes read [0-9]* but wanted [0-9]*')], ('Infrastructure - Artifactory', 'Operation failed'): [re.compile('^.*Non-zero return code from art_cli:.*')], ('Infrastructure - Artifactory', 'Operation timed out'): [re.compile(\"Error downloading 'https:\\\\/\\\\/(.*)\\\\.artifactory\\\\.cc\\\\.bmwgroup\\\\.net(.*)to(.*)\\\\: The operation has timed out\")], ('Infrastructure - Artifactory', 'Permission'): [re.compile('403 Client Error: Forbidden for url.*')], ('Infrastructure - Artifactory', 'Unknown host (ddad)'): [re.compile('Unknown\\\\shost:\\\\sddad\\\\.artifactory\\\\.cc\\\\.bmwgroup\\\\.net')], ('Infrastructure - Artifactory', 'Unknown host (codecraft)'): [re.compile('Unknown\\\\shost:\\\\scodecraft(.*)artifactory(.*)\\\\.cc\\\\.bmwgroup\\\\.net')], ('Infrastructure - Artifactory', 'Fetch failed'): [re.compile('ERROR:.+An error occurred during the fetch of repository.+(\\\\n.+){1,5}\\\\nError in download.+'), re.compile('^.*E: Failed to fetch https:\\\\/\\\\/.*artifactory\\\\.cc\\\\.bmwgroup\\\\.net\\\\/.* File has unexpected size \\\\(.* != .*\\\\)\\\\. Mirror sync in progress\\\\?.*$')], ('Infrastructure - Artifactory', 'Service unreachable'): [re.compile('artifactory\\\\.cc\\\\.bmwgroup\\\\.net[^\\\\s]*\\\\s(?P<details>[^\\\\(]*\\\\(?Service Unavailable\\\\)?)')], ('Infrastructure - Bazel remote cache', 'Inaccessible remote cache'): [re.compile('WARNING: Writing to Remote Cache:\\\\nio.grpc.StatusRuntimeException: UNKNOWN: operation not permitted'), re.compile('WARNING: Writing to Remote Cache:\\\\nio.grpc.StatusRuntimeException: UNKNOWN: EOF'), re.compile('ERROR: Failed to query remote execution capabilities: UNAVAILABLE: Unable to resolve host buildbarn\\\\.cc\\\\.bmwgroup\\\\.net'), re.compile('^java.io.IOException: io.grpc.StatusRuntimeException: UNAVAILABLE: Unable to resolve host buildbarn.cc.bmwgroup.net$')], ('Infrastructure - Bazel remote cache', 'Build without the bytes'): [re.compile(\"^ERROR: .* Failed to fetch file with hash '.*' because it does not exist remotely\\\\..*$\"), re.compile(\"^(?:\\\\s+|\\\\\\\\t)?(Suppressed: )?java\\\\.io\\\\.IOException: Failed to fetch file with hash '.*' because it does not exist remotely\\\\..*$\"), re.compile('ERROR: .* failed: failed to create _solib symbolic link .* to target .*: Missing digest: .*'), re.compile('ERROR: .*: Exec failed due to IOException: null'), re.compile('^ERROR: .*io\\\\.grpc\\\\.StatusRuntimeException: UNAVAILABLE: io exception.*$'), re.compile('^(java.io.IOException:|ERROR:).*io.grpc.StatusRuntimeException: UNAVAILABLE: upstream connect error or disconnect/reset before headers.*$')], ('Infrastructure - Bazel remote cache', 'Connection closed'): [re.compile('^.*Suppressed: java.io.IOException: An existing connection was forcibly closed by the remote host.*$')], ('Infrastructure - Bazel remote cache', 'Connection timed out'): [re.compile('ERROR: Failed to query remote execution capabilities: [Cc]onnection timed out.+$')], ('Infrastructure - Bazel remote cache', 'Connection refused'): [re.compile('ERROR: Failed to query remote execution capabilities: Connection refused'), re.compile('ERROR: Failed to query remote execution capabilities: finishConnect\\\\(\\\\.\\\\.\\\\) failed: Connection refused: buildbarn\\\\.cc\\\\.bmwgroup\\\\.net/.*$'), re.compile('^Caused by:.*UNAVAILABLE:.*connection error'), re.compile('^.*UNAVAILABLE.*connection error.*connection refused.*')], ('Infrastructure - Bazel remote cache', 'Deadline exceeded'): [re.compile('^.*DEADLINE_EXCEEDED:.*deadline exceeded.*')], ('Infrastructure - Bazel remote cache', 'Handshake timed out'): [re.compile('ERROR: Failed to query remote execution capabilities: handshake timed out after.+$')], ('Infrastructure - Bazel remote cache', 'Invalid Certificate'): [re.compile(\"^ERROR: Failed to init TLS infrastructure using '.*' as client certificate: File does not contain valid certificates: .*\")], ('Infrastructure - Bazel remote cache', 'No route to host'): [re.compile('ERROR: Failed to query remote execution capabilities: finishConnect\\\\(\\\\.\\\\.\\\\) failed: No route to host:.+$')], ('Infrastructure - Bazel remote cache', 'No healthy upstream'): [re.compile('^java.io.IOException: io.grpc.StatusRuntimeException: UNAVAILABLE: no healthy upstream$'), re.compile('^ERROR: .*io\\\\.grpc\\\\.StatusRuntimeException: UNAVAILABLE: no healthy upstream$')], ('Infrastructure - Bazel remote cache', 'Resource exhausted'): [re.compile('^ERROR:.*io\\\\.grpc\\\\.StatusRuntimeException: RESOURCE_EXHAUSTED.*$')], ('Infrastructure - Bazel remote cache', 'Resource not found'): [re.compile('^.*Traceback.+\\\\n( .+\\\\n)+.+ResourceNotFound.*')], ('Infrastructure - Bazel remote cache', 'Generic status runtime exception'): [re.compile('^ERROR:.+io\\\\.grpc\\\\.StatusRuntimeException:.+$')], ('Infrastructure - Bazel Remote Execution', 'Operation not found'): [re.compile('^ERROR: .+\\\\(Exit 34\\\\): NOT_FOUND: Operation not found:.+$')], ('Infrastructure - Bazel Remote Execution', 'Docker pull failed'): [re.compile('^ERROR: .+\\\\(Exit 34\\\\): INVALID_ARGUMENT: Unable to start docker container.+$')], ('Infrastructure - BES upload', 'Failure'): [re.compile('^ERROR: The Build Event Protocol upload failed.*')], ('Infrastructure - BES upload', 'Timeout'): [re.compile('^ERROR: The Build Event Protocol upload timed out.*')], ('Infrastructure - Bazel test logs reporter', ''): [re.compile('bazel_test_logs_reporter - Unexpected error: (?P<details>.+)')], ('Infrastructure - Git LFS', ''): [re.compile('^.*Request Time-out.*'), re.compile('batch response: Fatal error: (?P<details>.+)')], ('Infrastructure - PyPI server not responding (possible AF auth failure)', ''): [re.compile('Could not find a version that satisfies the requirement .+')], ('Infrastructure - Git', ''): [re.compile('Unable to checkout .+ in submodule path .+'), re.compile('error: failed to push .+'), re.compile(\"ERROR:.+An error occurred during the fetch of repository.+(\\\\n.+){1,}\\\\nError in fail: error running 'git fetch.+\"), re.compile('fatal:.+Could not read from remote repository.+')], ('Infrastructure - Docker', ''): [re.compile('=+\\\\n.+\\\\n=+\\\\n+Cannot connect to the Docker daemon .+'), re.compile('=+\\\\n.+\\\\n=+\\\\n+Error response .+'), re.compile('^.*Error: unable to pull ddad.artifactory.cc.bmwgroup.net.*'), re.compile('Error\\\\: error logging into \\\\\"ddad\\\\.artifactory\\\\.cc\\\\.bmwgroup\\\\.net\\\\\"\\\\: invalid username\\\\/password'), re.compile('Error response from daemon(.*)artifactory\\\\.cc\\\\.bmwgroup\\\\.net[^\\\\s]*\\\\s(?P<details>.*)'), re.compile('manifest for artifactory\\\\.cc\\\\.bmwgroup\\\\.net\\\\/.*\\\\:latest not found\\\\: manifest unknown\\\\: The named manifest is not known to the registry'), re.compile('^Error: Error parsing image configuration: unable to retrieve auth token: invalid username/password: unknown: Bad props auth token(:?).*$')], ('Infrastructure - Tasking licenses exhausted', ''): [re.compile('^(ctc|ltc) .*E109'), re.compile('^ERROR: (ctc|ltc) .*: protection error: .*License expired\\\\. No valid license found for.*')], ('Infrastructure - ZipArchive', ''): [re.compile('^failed to unpack .* to .*$')], ('Infrastructure - OpenShift CLI', ''): [re.compile('^Error from server \\\\(.*\\\\): .+$')], ('Infrastructure - Winrm failure', ''): [re.compile('winrm connection error: .+'), re.compile('winrm send_input failed'), re.compile('winrm connection error: HTTPSConnectionPool')], ('Infrastructure - xpad-build-integration', 'Copy ITF test images to cache server'): [re.compile(\"^cp: failed to close '\\\\/mnt\\\\/itf-images\\\\/.*': Input\\\\/output error$\")], ('Infrastructure - xpad-build-integration', 'Signing server unresolvable'): [re.compile('ssh: Could not resolve hostname xpad-ci-dev.sign.extern.cc.bmwgroup.net: Temporary failure in name resolution')], ('Infrastructure - xpad-build-integration', 'Signing server connection error'): [re.compile('connect to host xpad-ci-dev.sign.extern.cc.bmwgroup.net port 22: No route to host')], ('Infrastructure - xpad-build-integration', 'Signing failure'): [re.compile('^subprocess\\\\.CalledProcessError: Command .*/.xpad_sign\\\\/bin\\\\/sign.* returned non-zero exit status [1-9]*\\\\.$'), re.compile('^.*signature generation failed$')], ('Infrastructure - License Server', ''): [re.compile('FlexNet Licensing error:.*\\\\n.*'), re.compile('ERROR:(.*)Not able to obtain FlexLM license(.*)')], ('Infrastructure - License Server (CAS)', ''): [re.compile('ERROR:(.*)License request for vsxrtegenerator feature failed(.*)')], ('Infrastructure - License Server (QNX)', ''): [re.compile('Feature:.*kwbuildproject.*\\\\n.*License path:.*([0-9]{4})@([a-z+0-9]+).muc:.*\\\\n.*')], ('Infrastructure - Network', 'License'): [re.compile('^.*: protection error: .*Hostname lookup failed .* No valid license found for.*')], ('Infrastructure - Network', 'Traffic Monitoring'): [re.compile('^Could not find the requested service network_traffic_monitoring\\\\: host.*')], ('Infrastructure - IOException', ''): [re.compile('^.*Exec failed due to IOException.*')], ('Infrastructure - netrc', ''): [re.compile('ERROR: There was a problem ensuring netrc entries')], ('Infrastructure - Matlab License', ''): [re.compile('License checkout failed.')]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regex structure for understanding + imports\n",
    "\n",
    "import json\n",
    "import error_patterns\n",
    "import re\n",
    "\n",
    "INFRA_PATTERNS_TEST = {\n",
    "    \"Type1\":{\"r0\"},\n",
    "    \"Type2\":{\"\":[\"r1\", \"r2\",\"r3\"]},\n",
    "    \"Type3\":{\"Subtype1\":[\"r4\"]}\n",
    "}\n",
    "\n",
    "print(INFRA_PATTERNS_TEST)\n",
    "\n",
    "if \"r2\" == INFRA_PATTERNS_TEST[\"Type2\"][\"\"][1]:\n",
    "    print(\"true\")\n",
    "else:\n",
    "    print(\"false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compile the patterns from patterns.py\n",
    "import json\n",
    "import error_patterns\n",
    "import re\n",
    "INFRA_PATTERNS = error_patterns.INFRA_PATTERNS\n",
    "import os\n",
    "\n",
    "def compile_patterns(patterns_dict):\n",
    "    compiled_patterns = {}\n",
    "    for main_category, patterns in patterns_dict.items():\n",
    "        if isinstance(patterns, dict):\n",
    "            for sub_category, sub_patterns in patterns.items():\n",
    "                for pattern in sub_patterns:\n",
    "                    compiled_patterns.setdefault((main_category, sub_category), []).append(re.compile(pattern))\n",
    "        else:\n",
    "            for pattern in patterns:\n",
    "                compiled_patterns.setdefault((main_category, \"\"), []).append(re.compile(pattern))\n",
    "    return compiled_patterns\n",
    "\n",
    "# Compile the patterns\n",
    "compiled_infra_patterns = compile_patterns(INFRA_PATTERNS)\n",
    "\n",
    "# print(compiled_infra_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Working Code, Type + subtype, INFRA_PATTERN, file: ef7ce17ae108085e8a26e1f2046e1cf73e8c976_cropped.json\n",
    "\n",
    "def process_log_file(file_path, compiled_patterns):\n",
    "    with open(file_path, 'r') as file:\n",
    "        log_entries = json.load(file)\n",
    "        \n",
    "        # Iterate over the log entries\n",
    "        for entry in log_entries:\n",
    "            # Concatenate the stdout_lines if present into a single string\n",
    "            stdout_text = \"\\n\".join(entry['stdout_lines']) if 'stdout_lines' in entry else \"\"\n",
    "            # Check the concatenated stdout_lines against the compiled regex patterns\n",
    "            matches = check_log_entry(stdout_text, compiled_patterns)\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    main_category, sub_category, pattern = match\n",
    "                    print(f\"Main Category: {main_category}, Subcategory: {sub_category}, Pattern: {pattern}\")\n",
    "            else:\n",
    "                print(\"No matches found\")\n",
    "\n",
    "\n",
    "# Function to check a log entry against compiled patterns\n",
    "def check_log_entry(log_entry, compiled_patterns):\n",
    "    matches = []\n",
    "    for (main_category, sub_category), regex_list in compiled_patterns.items():\n",
    "        for regex in regex_list:\n",
    "            if regex.search(log_entry):\n",
    "                # If a subcategory exists, include it in the output\n",
    "                category = f\"{main_category} - {sub_category}\" if sub_category else main_category\n",
    "                # Append a tuple with the category, subcategory, and the matching pattern\n",
    "                matches.append((category, sub_category, regex.pattern))\n",
    "    return matches\n",
    "\n",
    "#USAGE:\n",
    "path_example_logfile = 'preprocessed_logs/9ef7ce17ae108085e8a26e1f2046e1cf73e8c976_cropped.json'\n",
    "\n",
    "process_log_file(path_example_logfile, compiled_infra_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### adding build patterns (not working rn)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict, defaultdict\n",
    "import error_patterns\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "INFRA_PATTERNS = error_patterns.INFRA_PATTERNS\n",
    "BUILD_PATTERNS = error_patterns.BUILD_PATTERNS\n",
    "\n",
    "\n",
    "def read_cropped_logs(directory_path):\n",
    "    \"\"\"\n",
    "    Read the cropped files and store them in a dictionary with ordered keys.\n",
    "\n",
    "    :param directory_path: The directory path to the JSON data files.\n",
    "    :return: A dictionary with filenames as keys and their corresponding JSON content as values.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    key_order = ['id', 'name', 'stderr', 'stdout_lines', 'node', 'msg']\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = json.load(file)\n",
    "                # Create a new ordered dictionary for each JSON object\n",
    "                ordered_file_content = [\n",
    "                    OrderedDict((k, content.get(k, None)) for k in key_order)\n",
    "                    for content in file_content\n",
    "                ]\n",
    "                # Use the filename as the key for the outer dictionary\n",
    "                data[filename] = {index: content for index, content in enumerate(ordered_file_content)}\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to compile the patterns\n",
    "def compile_patterns(patterns_dict):\n",
    "    compiled_patterns = defaultdict(list)\n",
    "    for category, patterns in patterns_dict.items():\n",
    "        for pattern in patterns:\n",
    "            compiled_patterns[category].append(re.compile(pattern))\n",
    "    return compiled_patterns\n",
    "\n",
    "# Function to label a single log entry\n",
    "def label_log_entry(log_entry, regex_list):\n",
    "    for regex in regex_list:\n",
    "        if 'msg' in log_entry and regex.search(log_entry['msg']):\n",
    "            return 'Infrastructure - Docker Build Failure'\n",
    "    print(log_entry[\"id\"], \n",
    "          log_entry[\"name\"],\n",
    "          log_entry[\"stderr\"],\n",
    "          log_entry[\"msg\"]\n",
    "         )\n",
    "    return 'Unknown'\n",
    "\n",
    "# Compile the patterns\n",
    "compiled_infra_patterns = compile_patterns(INFRA_PATTERNS)\n",
    "compiled_build_patterns = compile_patterns(BUILD_PATTERNS)\n",
    "\n",
    "#USAGE: \n",
    "cropped_logs_path = 'preprocessed_logs'\n",
    "log_data = read_cropped_logs(cropped_logs_path)\n",
    "\n",
    "# Extract the first log entry from the nested data\n",
    "first_file_key = next(iter(log_data))\n",
    "first_log_entry = log_data[first_file_key][0]\n",
    "\n",
    "# Label the first log entry\n",
    "# Pass the list of compiled Infrastructure - Docker patterns directly to the label_log_entry function\n",
    "label = label_log_entry(first_log_entry, compiled_infra_patterns)\n",
    "print(f\"The label for the first log entry is: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
