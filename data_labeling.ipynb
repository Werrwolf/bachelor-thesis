{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checklist for logs: \n",
    "\n",
    "|job ID|log| reason acc. to elasticsearch | reason acc to script| |\n",
    "|-|----------|----------|----------|-----|\n",
    "| baf77c21-bdd5-0aa2-8731-000000000385|9ef7ce17ae108085e8a26e1f2046e1cf73e8c976.json|Infrastructure - Matlab License |Infrastructure - Matlab License |y|\n",
    "| 86623622-6e74-9368-74a8-000000000028|882dafcc748b4f0695ce486241a05ad2.json|?| Test(s) failed|y|\n",
    "|16911dd9-d58b-df18-7329-000000000ba3|e850514f59cb3334754f2641fc63f20f46af56e7.json|FuSa Violation found|Main Category: FuSa Violation Found (Check 'bazel_wrapper_log.txt' on the logs folder), Subcategory: , Pattern: Failed actions detected in bazel_wrapper_log.txt file|y|\n",
    "|No ID provided||?|redirected output - Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components, Subcategory: Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components|?|\n",
    "|No ID provided||?| redirected output - default, Subcategory: default|?|\n",
    "|c65a4cd1-edf7-790d-cd51-000000000042|0752ac127d21a70af1765ae29afc53d978224f25.json|python|Test(s) failed, Subcategory: |?|\n",
    "|No ID provided||python|Main Category: python, Subcategory: ,|y||\n",
    "|b6d2a4bc-700f-7546-f838-000000000042|8e89be688f5b331654a6f44975a7c6c23dd3b71c.json|Compiler (gnu)  | Bazel - error executing command, Subcategory: error executing command|X|\n",
    "||00e0b3d030f7fd0eef0c4b016e3d5e7e2b51a69f.json|Bazel (failed on target analysis)|Not flagged / No match found|X|\n",
    "|No ID provided|b819bae8dfb1923b8f9dc3c1b4bb2eed8c3fa2a3.json|Compiler (clang)|Bazel - error executing command, Subcategory: error executing command|X|\n",
    "|NO ID provided|cd5c0bbd5821d9d31f41442f78bcae86221e65a0.json|Bazel(missing input file)|Bazel - missing input file, Subcategory: missing input file, Pattern: ERROR:(.*)input file\\(s\\) do not exist |?|\n",
    "|NO ID provided||Bazel(missing input file)|Bazel - missing input file, Subcategory: missing input file, Pattern: ERROR:(.*)missing input file '.*' |?|\n",
    "\n",
    "Why same file gets \"unknown error\" & a match? -->  Because 18 logs but 34 errors - Needs Dealing with\n",
    "- 005fc583d4745e2470010c57b6422bcbc5c5fb0e271a7f11d72248e702e1090a (2 times)\n",
    "- 0067a8788a1a5e30cecc3c159a8f5b6546a46cd5fb18253c82de30e8d1e7a988 (4 times)\n",
    "- 0077401c9568efb6267a2c6ffd1e696ffe70e479d7c5e69413d3d7aea3105035 (4 times)\n",
    "- e850514f59cb3334754f2641fc63f20f46af56e7 (6 times)\n",
    "- 0079e5bcee8a7318e88e6d40be15c242ad522e2af6cbc1cdbeecf4beb0e743c7 (3 times)\n",
    "- 0752ac127d21a70af1765ae29afc53d978224f25 (4 times)\n",
    "- 8e89be688f5b331654a6f44975a7c6c23dd3b71c (3 times)\n",
    "- 9ef7ce17ae108085e8a26e1f2046e1cf73e8c976 (2 times)\n",
    "- cd5c0bbd5821d9d31f41442f78bcae86221e65a0 (2 times)\n",
    "\n",
    "- fix inconsistencies in pattern? \n",
    "- fix script for all cases ( decision!) --> use existing _find_errors ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current File: preprocessed_logs\\005fc583d4745e2470010c57b6422bcbc5c5fb0e271a7f11d72248e702e1090a__job-output_cropped.json\n",
      "docker-run (ID: 2aa698b8-b2fd-a900-8da6-00000000002d)\n",
      "Error Cluster: Test(s) failed, Error Type: , Flagged Pattern: \\/\\/.*\\s+FAILED in [0-9.]+s\n",
      "Current File: preprocessed_logs\\00609ed82bfdb509cf935a6101a636b891e25ef1a08268849b236609f42650d3__job-output_cropped.json\n",
      "bazel-execute (ID: 620460c8-edcb-fb02-f8d4-000000000333)\n",
      "Error Cluster: Test(s) failed, Error Type: , Flagged Pattern: \\/\\/.*\\s+FAILED in [0-9.]+s\n",
      "Current File: preprocessed_logs\\0063c906e5290ca5c11bc7c8efba154fc8dcbcb03643bcda0f54f793bd9af5b5__job-output_cropped.json\n",
      "docker-run (ID: ea446e25-7667-a36d-6c98-000000000028)\n",
      "Error Cluster: Test(s) failed, Error Type: , Flagged Pattern: \\/\\/.*\\s+FAILED in [0-9.]+s\n",
      "Current File: preprocessed_logs\\0065bc74ca0b24d30a11b96a73f1fb8588a624962b67bec41fcde6a862c5acb9__job-output_cropped.json\n",
      "docker-exec (ID: aa463074-4aee-806c-398d-0000000000cf)\n",
      "Error Cluster: Bazel - error executing command, Error Type: error executing command, Flagged Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "Current File: preprocessed_logs\\0067a8788a1a5e30cecc3c159a8f5b6546a46cd5fb18253c82de30e8d1e7a988__job-output_cropped.json\n",
      "docker-run (ID: fec01ff5-970b-89c8-db0d-000000000042)\n",
      "Error Cluster: Test(s) failed to build, Error Type: , Flagged Pattern: \\/\\/.*\\s+FAILED TO BUILD[$]?\n",
      "Current File: preprocessed_logs\\0067a8788a1a5e30cecc3c159a8f5b6546a46cd5fb18253c82de30e8d1e7a988__job-output_cropped.json\n",
      "docker-run (ID: fec01ff5-970b-89c8-db0d-000000000042)\n",
      "Error Cluster: Bazel - error executing command, Error Type: error executing command, Flagged Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "Current File: preprocessed_logs\\0077401c9568efb6267a2c6ffd1e696ffe70e479d7c5e69413d3d7aea3105035__job-output_cropped.json\n",
      "docker-run (ID: 5e31fc0c-7743-17c7-e392-000000000042)\n",
      "Error Cluster: Test(s) failed to build, Error Type: , Flagged Pattern: \\/\\/.*\\s+FAILED TO BUILD[$]?\n",
      "Current File: preprocessed_logs\\0077401c9568efb6267a2c6ffd1e696ffe70e479d7c5e69413d3d7aea3105035__job-output_cropped.json\n",
      "docker-run (ID: 5e31fc0c-7743-17c7-e392-000000000042)\n",
      "Error Cluster: Bazel - error executing command, Error Type: error executing command, Flagged Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "Current File: preprocessed_logs\\0079e5bcee8a7318e88e6d40be15c242ad522e2af6cbc1cdbeecf4beb0e743c7__job-output_cropped.json\n",
      "test-guide-connector (ID: ee176fa9-7af9-a6a0-2034-000000000721)\n",
      "Error Cluster: Test Guide - connector, Error Type: connector, Flagged Pattern: \\[INFO \\] .* Test Guide connector terminated with error...\n",
      "Current File: preprocessed_logs\\0079e5bcee8a7318e88e6d40be15c242ad522e2af6cbc1cdbeecf4beb0e743c7__job-output_cropped.json\n",
      "check-junit-verdict (ID: ee176fa9-7af9-a6a0-2034-000000000a56)\n",
      "Error Cluster: Test Guide - Tests failing, Error Type: Tests failing, Flagged Pattern: Tests still failing after all excludes\n",
      "Current File: preprocessed_logs\\0752ac127d21a70af1765ae29afc53d978224f25_cropped.json\n",
      "docker-run (ID: c65a4cd1-edf7-790d-cd51-000000000042)\n",
      "Error Cluster: Test(s) failed, Error Type: , Flagged Pattern: \\/\\/.*\\s+FAILED in [0-9]* out of [0-9]*\n",
      "Current File: preprocessed_logs\\0752ac127d21a70af1765ae29afc53d978224f25_cropped.json\n",
      "No task name provided (ID: No id provided)\n",
      "Error Cluster: python, Error Type: , Flagged Pattern: ^(.*Traceback.+\\n( .+\\n)+(?P<type>\\S.+Error.*?):.+\\n?(?P<details>(\\s.+\\n)*)?)+\n",
      "Current File: preprocessed_logs\\882dafcc748b4f0695ce486241a05ad2_cropped.json\n",
      "docker-run (ID: 86623622-6e74-9368-74a8-000000000028)\n",
      "Error Cluster: Test(s) failed, Error Type: , Flagged Pattern: \\/\\/.*\\s+FAILED in [0-9]* out of [0-9]*\n",
      "Current File: preprocessed_logs\\8e89be688f5b331654a6f44975a7c6c23dd3b71c_cropped.json\n",
      "docker-run (ID: b6d2a4bc-700f-7546-f838-000000000042)\n",
      "Error Cluster: Bazel - error executing command, Error Type: error executing command, Flagged Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "Current File: preprocessed_logs\\9ef7ce17ae108085e8a26e1f2046e1cf73e8c976_cropped.json\n",
      "docker-run (ID: baf77c21-bdd5-0aa2-8731-000000000385)\n",
      "Error Cluster: Infrastructure - Matlab License, Error Type: , Flagged Pattern: License checkout failed.\n",
      "Current File: preprocessed_logs\\9ef7ce17ae108085e8a26e1f2046e1cf73e8c976_cropped.json\n",
      "docker-run (ID: baf77c21-bdd5-0aa2-8731-000000000385)\n",
      "Error Cluster: Bazel - error executing command, Error Type: error executing command, Flagged Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "Current File: preprocessed_logs\\b819bae8dfb1923b8f9dc3c1b4bb2eed8c3fa2a3_cropped.json\n",
      "No task name provided (ID: No id provided)\n",
      "Error Cluster: Bazel - error executing command, Error Type: error executing command, Flagged Pattern: ERROR:.{1,500}error executing command \\(.*\\)\n",
      "Current File: preprocessed_logs\\cd5c0bbd5821d9d31f41442f78bcae86221e65a0_cropped.json\n",
      "No task name provided (ID: No id provided)\n",
      "Error Cluster: Bazel - missing input file, Error Type: missing input file, Flagged Pattern: ERROR:(.*)input file\\(s\\) do not exist\n",
      "Current File: preprocessed_logs\\cd5c0bbd5821d9d31f41442f78bcae86221e65a0_cropped.json\n",
      "No task name provided (ID: No id provided)\n",
      "Error Cluster: Bazel - missing input file, Error Type: missing input file, Flagged Pattern: ERROR:(.*)missing input file '.*'\n",
      "Current File: preprocessed_logs\\e850514f59cb3334754f2641fc63f20f46af56e7_cropped.json\n",
      "docker-run-fusa (ID: 16911dd9-d58b-df18-7329-000000000ba3)\n",
      "Error Cluster: FuSa Violation Found (Check 'bazel_wrapper_log.txt' on the logs folder), Error Type: , Flagged Pattern: Failed actions detected in bazel_wrapper_log.txt file\n",
      "Current File: preprocessed_logs\\e850514f59cb3334754f2641fc63f20f46af56e7_cropped.json\n",
      "No task name provided (ID: No id provided)\n",
      "Error Cluster: redirected output - Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components, Error Type: Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components, Flagged Pattern: ^@tu-cc-ci-adp-github-eof(?:(?:\\s+type:(?P<type>\\S*))|(?:\\s+file:(?P<file>\\S*))|(?:\\s+line:(?P<line>\\S*)))*\\s+(?P<details>(?:.|[\\r\\n])*(- Check-Bazel-rules-in-FuSa-critical-components)(?:.|[\\r\\n])*)\n",
      "Current File: preprocessed_logs\\e850514f59cb3334754f2641fc63f20f46af56e7_cropped.json\n",
      "No task name provided (ID: No id provided)\n",
      "Error Cluster: redirected output - default, Error Type: default, Flagged Pattern: ^@tu-cc-ci-adp-github-eof(?:(?:\\s+type:(?P<type>\\S*))|(?:\\s+file:(?P<file>\\S*))|(?:\\s+line:(?P<line>\\S*)))*\\s+(?P<details>(?:.|[\\r\\n])*)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import extract_build_failures.error_patterns as error_patterns\n",
    "import re\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Example patterns for testing\n",
    "INFRA_PATTERNS = error_patterns.INFRA_PATTERNS\n",
    "BUILD_PATTERNS = error_patterns.BUILD_PATTERNS\n",
    "\n",
    "def restructure_patterns(patterns):\n",
    "    \"\"\"\n",
    "    Restructure imported patterns to a consistent format.\n",
    "    \n",
    "    Args:\n",
    "        patterns (dict): The original patterns dictionary.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The restructured patterns dictionary.\n",
    "    \"\"\"\n",
    "    restructured_patterns = {}\n",
    "    \n",
    "    for pattern_type, subpatterns in patterns.items():\n",
    "        if isinstance(subpatterns, (set, list)):\n",
    "            restructured_patterns[pattern_type] = {\"\": list(subpatterns)}\n",
    "        elif isinstance(subpatterns, dict):\n",
    "            restructured_patterns[pattern_type] = {}\n",
    "            for subtype, regex_list in subpatterns.items():\n",
    "                if isinstance(regex_list, (list, set)):\n",
    "                    restructured_patterns[pattern_type][subtype] = list(regex_list)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected type for regex list: {type(regex_list)}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected type for subpatterns: {type(subpatterns)}\")\n",
    "    \n",
    "    return restructured_patterns\n",
    "\n",
    "def compile_patterns(patterns_dict):\n",
    "    \"\"\"\n",
    "    Compile regex patterns from the restructured patterns dictionary.\n",
    "    \n",
    "    Args:\n",
    "        patterns_dict (dict): The restructured patterns dictionary.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The compiled regex patterns.\n",
    "    \"\"\"\n",
    "    compiled_patterns = {}\n",
    "    for main_category, subpatterns in patterns_dict.items():\n",
    "        for sub_category, patterns in subpatterns.items():\n",
    "            for pattern in patterns:\n",
    "                compiled_patterns.setdefault((main_category, sub_category), []).append(re.compile(pattern))\n",
    "    return compiled_patterns\n",
    "\n",
    "def check_log_entry(log_entry, compiled_patterns):\n",
    "    \"\"\"\n",
    "    Check a log entry against compiled regex patterns.\n",
    "    \n",
    "    Args:\n",
    "        log_entry (str): The log entry to check.\n",
    "        compiled_patterns (dict): The compiled regex patterns.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of matches found in the log entry.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for (main_category, sub_category), regex_list in compiled_patterns.items():\n",
    "        for regex in regex_list:\n",
    "            if regex.search(log_entry):\n",
    "                category = f\"{main_category} - {sub_category}\" if sub_category else main_category\n",
    "                matches.append((category, sub_category, regex.pattern))\n",
    "    return matches\n",
    "\n",
    "def process_log_files(directory_path, compiled_patterns):\n",
    "    \"\"\"\n",
    "    Process log files in the specified directory and summarize the findings.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): The path to the directory containing log files.\n",
    "        compiled_patterns (dict): The compiled regex patterns.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A summary of the findings.\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'tasks_summary': {},\n",
    "        'msg_summary': {}\n",
    "    }\n",
    "    for filename in filter(lambda f: f.endswith('.json'), os.listdir(directory_path)):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            log_entries = json.load(file)\n",
    "            for log in log_entries:\n",
    "                task_id = log.get('id', 'No ID provided')\n",
    "                name = log.get('name', 'No task name provided')\n",
    "                msg = log['msg']\n",
    "                task_key = f\"{name} (ID: {task_id})\"\n",
    "                summary['tasks_summary'].setdefault(task_key, 0)\n",
    "                summary['tasks_summary'][task_key] += 1\n",
    "                summary['msg_summary'].setdefault(msg, 0)\n",
    "                summary['msg_summary'][msg] += 1\n",
    "\n",
    "                stdout_text = \"\\n\".join(log.get('stdout_lines', []))\n",
    "                matches = check_log_entry(stdout_text, compiled_patterns)\n",
    "                for match in matches:\n",
    "                    error_cluster, error_type, pattern = match\n",
    "                    print(f\"Current File: {file_path}\")\n",
    "                    print(task_key)\n",
    "                    print(f\"Error Cluster: {error_cluster}, Error Type: {error_type}, Flagged Pattern: {pattern}\")\n",
    "    return summary\n",
    "\n",
    "def format_summary_to_screen_width(summary, terminal_width=150):\n",
    "    \"\"\"\n",
    "    Format the summary to fit the screen width.\n",
    "    \n",
    "    Args:\n",
    "        summary (dict): The summary to format.\n",
    "        terminal_width (int): The width of the terminal.\n",
    "        \n",
    "    Returns:\n",
    "        str: The formatted summary.\n",
    "    \"\"\"\n",
    "    formatted_summary = \"\"\n",
    "    for key, value in summary.items():\n",
    "        if isinstance(value, dict):\n",
    "            formatted_summary += f\"{key}:\\n\"\n",
    "            for sub_key, sub_value in value.items():\n",
    "                wrapped_sub_value = textwrap.fill(str(sub_value), terminal_width - 4)\n",
    "                formatted_summary += f\"  {sub_key}: {wrapped_sub_value}\\n\"\n",
    "        else:\n",
    "            wrapped_value = textwrap.fill(str(value), terminal_width)\n",
    "            formatted_summary += f\"{key}: {wrapped_value}\\n\"\n",
    "        formatted_summary += \"-\" * terminal_width + \"\\n\"\n",
    "    return formatted_summary\n",
    "\n",
    "# Usage:\n",
    "# Restructure the patterns first\n",
    "restructured_infra_patterns = restructure_patterns(INFRA_PATTERNS)\n",
    "restructured_build_patterns = restructure_patterns(BUILD_PATTERNS)\n",
    "\n",
    "# Compile the restructured patterns\n",
    "compiled_infra_patterns = compile_patterns(restructured_infra_patterns)\n",
    "compiled_build_patterns = compile_patterns(restructured_build_patterns)\n",
    "\n",
    "# Combine all compiled patterns\n",
    "all_compiled_patterns = {**compiled_infra_patterns, **compiled_build_patterns}\n",
    "\n",
    "# Process log files\n",
    "directory_path = 'preprocessed_logs'\n",
    "summary = process_log_files(directory_path, all_compiled_patterns)\n",
    "\n",
    "# Format and print the summary\n",
    "# formatted_summary = format_summary_to_screen_width(summary)\n",
    "# print(formatted_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
