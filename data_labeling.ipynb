{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checklist for logs: \n",
    "\n",
    "|job ID|log| reason acc. to elasticsearch | reason acc to script| |\n",
    "|-|----------|----------|----------|-----|\n",
    "| baf77c21-bdd5-0aa2-8731-000000000385|9ef7ce17ae108085e8a26e1f2046e1cf73e8c976.json|Infrastructure - Matlab License |Infrastructure - Matlab License |y|\n",
    "| 86623622-6e74-9368-74a8-000000000028|882dafcc748b4f0695ce486241a05ad2.json|?| Test(s) failed|y|\n",
    "|16911dd9-d58b-df18-7329-000000000ba3|e850514f59cb3334754f2641fc63f20f46af56e7.json|FuSa Violation found|Main Category: FuSa Violation Found (Check 'bazel_wrapper_log.txt' on the logs folder), Subcategory: , Pattern: Failed actions detected in bazel_wrapper_log.txt file|y|\n",
    "|No ID provided||?|redirected output - Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components, Subcategory: Fusa Small Checks - Check-Bazel-rules-in-FuSa-critical-components|?|\n",
    "|No ID provided||?| redirected output - default, Subcategory: default|?|\n",
    "|c65a4cd1-edf7-790d-cd51-000000000042|0752ac127d21a70af1765ae29afc53d978224f25.json|python|Test(s) failed, Subcategory: |?|\n",
    "|No ID provided||python|Main Category: python, Subcategory: ,|y||\n",
    "|b6d2a4bc-700f-7546-f838-000000000042|8e89be688f5b331654a6f44975a7c6c23dd3b71c.json|Compiler (gnu)  | Bazel - error executing command, Subcategory: error executing command|X|\n",
    "||00e0b3d030f7fd0eef0c4b016e3d5e7e2b51a69f.json|Bazel (failed on target analysis)|Not flagged / No match found|X|\n",
    "|No ID provided|b819bae8dfb1923b8f9dc3c1b4bb2eed8c3fa2a3.json|Compiler (clang)|Bazel - error executing command, Subcategory: error executing command|X|\n",
    "|NO ID provided|cd5c0bbd5821d9d31f41442f78bcae86221e65a0.json|Bazel(missing input file)|Bazel - missing input file, Subcategory: missing input file, Pattern: ERROR:(.*)input file\\(s\\) do not exist |?|\n",
    "|NO ID provided||Bazel(missing input file)|Bazel - missing input file, Subcategory: missing input file, Pattern: ERROR:(.*)missing input file '.*' |?|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import extract_build_failures.error_patterns as error_patterns\n",
    "import re\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "INFRA_PATTERNS = error_patterns.INFRA_PATTERNS\n",
    "BUILD_PATTERNS = error_patterns.BUILD_PATTERNS\n",
    "\n",
    "def restructure_patterns(patterns):\n",
    "    \"\"\"\n",
    "    Restructure imported patterns to a consistent format.\n",
    "    \n",
    "    Args:\n",
    "        patterns (dict): The original patterns dictionary.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The restructured patterns dictionary.\n",
    "    \"\"\"\n",
    "    restructured_patterns = {}\n",
    "    for pattern_type, subpatterns in patterns.items():\n",
    "        if isinstance(subpatterns, (set, list)):\n",
    "            restructured_patterns[pattern_type] = {\"\": list(subpatterns)}\n",
    "        elif isinstance(subpatterns, dict):\n",
    "            restructured_patterns[pattern_type] = {}\n",
    "            for subtype, regex_list in subpatterns.items():\n",
    "                if isinstance(regex_list, (list, set)):\n",
    "                    restructured_patterns[pattern_type][subtype] = list(regex_list)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected type for regex list: {type(regex_list)}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected type for subpatterns: {type(subpatterns)}\")\n",
    "        \n",
    "        # Log the restructured patterns for comparison\n",
    "        # print(f\"Restructured patterns for {pattern_type}: {restructured_patterns[pattern_type]}\")\n",
    "    \n",
    "    return restructured_patterns\n",
    "\n",
    "def compile_patterns(patterns_dict):\n",
    "    \"\"\"\n",
    "    Compile regex patterns from the restructured patterns dictionary.\n",
    "    \n",
    "    Args:\n",
    "        patterns_dict (dict): The restructured patterns dictionary.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The compiled regex patterns.\n",
    "    \"\"\"\n",
    "    compiled_patterns = {}\n",
    "    for main_category, subpatterns in patterns_dict.items():\n",
    "        for sub_category, patterns in subpatterns.items():\n",
    "            for pattern in patterns:\n",
    "                compiled_patterns.setdefault((main_category, sub_category), []).append(re.compile(pattern))\n",
    "    return compiled_patterns\n",
    "\n",
    "def check_log_entry(log_entry, compiled_patterns):\n",
    "    \"\"\"\n",
    "    Check a log entry against compiled regex patterns.\n",
    "    \n",
    "    Args:\n",
    "        log_entry (str): The log entry to check.\n",
    "        compiled_patterns (dict): The compiled regex patterns.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of matches found in the log entry.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for (main_category, sub_category), regex_list in compiled_patterns.items():\n",
    "        for regex in regex_list:\n",
    "            if regex.search(log_entry):\n",
    "                category = f\"{main_category} - {sub_category}\" if sub_category else main_category\n",
    "                matches.append((category, sub_category, regex.pattern))\n",
    "    return matches\n",
    "\n",
    "def process_log_files(directory_path, compiled_patterns):\n",
    "    \"\"\"\n",
    "    Process log files in the specified directory and summarize the findings.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): The path to the directory containing log files.\n",
    "        compiled_patterns (dict): The compiled regex patterns.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A summary of the findings.\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'tasks_summary': {},\n",
    "        'msg_summary': {}\n",
    "    }\n",
    "    file_matches = {}\n",
    "    for filename in filter(lambda f: f.endswith('.json'), os.listdir(directory_path)):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        file_matches[file_path] = {}\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            log_entries = json.load(file)\n",
    "            for log in log_entries:\n",
    "                task_id = log.get('id', 'No ID provided')\n",
    "                name = log.get('name', 'No task name provided')\n",
    "                msg = log['msg']\n",
    "                task_key = f\"{name} (ID: {task_id})\"\n",
    "                summary['tasks_summary'].setdefault(task_key, 0)\n",
    "                summary['tasks_summary'][task_key] += 1\n",
    "                summary['msg_summary'].setdefault(msg, 0)\n",
    "                summary['msg_summary'][msg] += 1\n",
    "\n",
    "                stdout_text = \"\\n\".join(log.get('stdout_lines', []))\n",
    "                matches = check_log_entry(stdout_text, compiled_patterns)\n",
    "                if matches:\n",
    "                    if task_key not in file_matches[file_path]:\n",
    "                        file_matches[file_path][task_key] = []\n",
    "                    file_matches[file_path][task_key].extend(matches)\n",
    "    \n",
    "    return summary, file_matches\n",
    "\n",
    "def format_summary_to_screen_width(summary, terminal_width=150):\n",
    "    \"\"\"\n",
    "    Format the summary to fit the screen width.\n",
    "    \n",
    "    Args:\n",
    "        summary (dict): The summary to format.\n",
    "        terminal_width (int): The width of the terminal.\n",
    "        \n",
    "    Returns:\n",
    "        str: The formatted summary.\n",
    "    \"\"\"\n",
    "    formatted_summary = \"\"\n",
    "    for key, value in summary.items():\n",
    "        if isinstance(value, dict):\n",
    "            formatted_summary += f\"{key}:\\n\"\n",
    "            for sub_key, sub_value in value.items():\n",
    "                wrapped_sub_value = textwrap.fill(str(sub_value), terminal_width - 4)\n",
    "                formatted_summary += f\"  {sub_key}: {wrapped_sub_value}\\n\"\n",
    "        else:\n",
    "            wrapped_value = textwrap.fill(str(value), terminal_width)\n",
    "            formatted_summary += f\"{key}: {wrapped_value}\\n\"\n",
    "        formatted_summary += \"-\" * terminal_width + \"\\n\"\n",
    "    return formatted_summary\n",
    "\n",
    "def format_file_matches(file_matches, terminal_width=150):\n",
    "    \"\"\"\n",
    "    Format the file matches to fit the screen width.\n",
    "    \n",
    "    Args:\n",
    "        file_matches (dict): The file matches to format.\n",
    "        terminal_width (int): The width of the terminal.\n",
    "        \n",
    "    Returns:\n",
    "        str: The formatted file matches.\n",
    "    \"\"\"\n",
    "    formatted_matches = \"\"\n",
    "    for file_path, tasks in file_matches.items():\n",
    "        formatted_matches += f\"File: {file_path}\\n\"\n",
    "        for task_key, matches in tasks.items():\n",
    "            formatted_matches += f\"  Task: {task_key}\\n\"\n",
    "            for match in matches:\n",
    "                error_cluster, error_type, pattern = match\n",
    "                formatted_matches += f\"    Error Cluster: {error_cluster}, Error Type: {error_type}, Pattern: {pattern}\\n\"\n",
    "        formatted_matches += \"-\" * terminal_width + \"\\n\"\n",
    "    return formatted_matches\n",
    "\n",
    "# Usage:\n",
    "# Restructure the patterns first\n",
    "restructured_infra_patterns = restructure_patterns(INFRA_PATTERNS)\n",
    "restructured_build_patterns = restructure_patterns(BUILD_PATTERNS)\n",
    "\n",
    "# Compile the restructured patterns\n",
    "compiled_infra_patterns = compile_patterns(restructured_infra_patterns)\n",
    "compiled_build_patterns = compile_patterns(restructured_build_patterns)\n",
    "\n",
    "# Combine all compiled patterns\n",
    "all_compiled_patterns = {**compiled_infra_patterns, **compiled_build_patterns}\n",
    "\n",
    "# Process log files\n",
    "directory_path = 'preprocessed_logs'\n",
    "summary, file_matches = process_log_files(directory_path, all_compiled_patterns)\n",
    "\n",
    "# Format and print the summary\n",
    "# formatted_summary = format_summary_to_screen_width(summary)\n",
    "# print(formatted_summary)\n",
    "\n",
    "# Format and print the file matches\n",
    "formatted_file_matches = format_file_matches(file_matches)\n",
    "print(formatted_file_matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
